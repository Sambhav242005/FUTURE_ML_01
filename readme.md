# ğŸï¸ Classicâ€‘Cars SalesÂ â€” ModelÂ Comparison

A small, selfâ€‘contained project that trains four regression models on the ClassicÂ Cars sales dataset and lets you explore their performance in an interactive **Gradio** app.

---

## ğŸ“‹ Features

| Component            | Description                                                                   |
| -------------------- | ----------------------------------------------------------------------------- |
| **Data cleaning**    | Drops PII / sparse columns, labelâ€‘encodes categorical features.               |
| **Models**           | LinearÂ Regression, GradientÂ Boosting, RandomÂ Forest, and a Stacking ensemble. |
| **Target transform** | UsesÂ `log1p` / `expm1` via `TransformedTargetRegressor` for stability.        |
| **Metrics**          | Mean Absolute Error (MAE) & Mean Absolute Percentage Error (MAPE).            |
| **UI**               | Oneâ€‘click â€œRun comparisonâ€ button, interactive table, and MAE barâ€‘chart.      |

---

## ğŸš€ QuickÂ start

```bash
# 1. Clone / download the repo
git clone https://github.com/Sambhav242005/FUTURE_ML_01.git
# 2. Install dependencies
pip install -r requirements.txt

# 3. Launch the Gradio app
python main.py

# 4. Go to Browser enter this url to access it
http://127.0.0.1:7860

```

Your browser will open automatically. Click **Run comparison** to trigger training (â‰ˆ10Â s on a modern laptop). Results are cached, so subsequent clicks are instant.

---

## ğŸ—‚ï¸ Project structure

```
.
â”œâ”€â”€ main.py                     # Main script model run & UI
â”œâ”€â”€ data.py                     # load_sales_dataset(), assign_numbers()
â”œâ”€â”€ helper.py                   # Helper modules
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ README.md                   # You are here
```

---

## ğŸ› ï¸ Customisation

### Add or remove models

Edit the `models` dict in **sales\_model\_comparison.py**:

```python
models = {
    "Linear Regression": LinearRegression(),
    "XGBoost": XGBRegressor(tree_method="hist"),  # example
}
```

### Hyperâ€‘parameter tuning

Swap `GradientBoostingRegressor` / `RandomForestRegressor` for the HistGradientBoosting or plug in `GridSearchCV` inside `make_regression_pipeline()`.

### Additional metrics

Extend `evaluate_model()` with RMSE, RÂ², etc.

---

## ğŸ“‘ License

Released under the MIT License â€” see `LICENSE` for details.
